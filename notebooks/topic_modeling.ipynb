{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcd1d7d",
   "metadata": {},
   "source": [
    "Comparing Topic Models for Each Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1dbef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca926c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r reddit_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7101f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/home/beherya/nltk_data/corpora/stopwords')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find(\"corpora/stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e508d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcd6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = set([\n",
    "    'like', 'get', 'dont', 'im', 'would', 'really', 'one', 'people',\n",
    "    'time', 'know', 'feel', 'even', 'go', 'want', 'think', 'much',\n",
    "    'life', 'day', 'days', 'years', 'year', 'something', 'nothing',\n",
    "    'got', 'make', 'feeling', 'going', 'things', 'way', 'work',\n",
    "    'help', 'cant', 'need', 'see', 'friends', 'family', 'ive', 'anyone',\n",
    "    'anything', 'always', 'else', 'getting', 'started'\n",
    "])\n",
    "\n",
    "full_stop_words = base_stopwords.union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85dfebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a875268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(df, text_col, title, n_topics=5, n_top_words=10):\n",
    "    \"\"\"\n",
    "    Runs and prints topic models for a given DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\" {title} (n={len(df)} posts) \")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if len(df) < n_topics:\n",
    "        print(f\"Not enough documents to model {n_topics} topics. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # 1. Vectorize: Convert text to a word-count matrix\n",
    "    # We apply our preprocessing and stopword removal here\n",
    "    vectorizer = CountVectorizer(\n",
    "        preprocessor=preprocess_text,\n",
    "        stop_words=list(full_stop_words),\n",
    "        max_df=0.9,  # Ignore words in > 90% of docs\n",
    "        min_df=10,   # Ignore words in < 10 docs\n",
    "        ngram_range=(1, 1) # Only use single words\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        dtm = vectorizer.fit_transform(df[text_col])\n",
    "    except ValueError as e:\n",
    "        print(f\"Error vectorizing text (maybe all words were stopwords?): {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Model: Run Latent Dirichlet Allocation\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        random_state=42, # For reproducible results\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    lda.fit(dtm)\n",
    "\n",
    "    # 3. Display: Print the top words for each topic\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        # Get the indices of the top words\n",
    "        top_words_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        # Get the words themselves\n",
    "        top_words = [feature_names[i] for i in top_words_indices]\n",
    "        print(f\"Topic {topic_idx + 1}: {' '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e22ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_covid_df = reddit_sent_df[reddit_sent_df[\"covid_period\"] == \"Pre-COVID\"]\n",
    "during_covid_df = reddit_sent_df[reddit_sent_df[\"covid_period\"] == \"During COVID\"]\n",
    "post_covid_df = reddit_sent_df[reddit_sent_df[\"covid_period\"] == \"Post-COVID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5830d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " Pre-COVID Topics (n=576 posts) \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beherya/code/schooling/northwestern-senior/glb_hlth_final_project/env/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'hadnt', 'hasnt', 'havent', 'hed', 'hell', 'hes', 'id', 'ill', 'isnt', 'itd', 'itll', 'mightnt', 'mustnt', 'neednt', 'shant', 'shed', 'shell', 'shes', 'shouldnt', 'shouldve', 'thatll', 'theyd', 'theyll', 'theyre', 'theyve', 'wasnt', 'wed', 'well', 'werent', 'weve', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: fucking everyone alone someone love nye never hate fuck many\n",
      "Topic 2: mental anxiety health didnt first school felt back night since\n",
      "Topic 3: anxiety bad good person happy anxious someone everything tired talk\n",
      "Topic 4: new happy alone everyone better everything anxiety anymore hope shit\n",
      "Topic 5: anxiety panic attack sleep never someone told depression job pain\n",
      "\n",
      "==================================================\n",
      " During-COVID Topics (n=10517 posts) \n",
      "==================================================\n",
      "Topic 1: anxiety anxious panic also sleep attack bad attacks take heart\n",
      "Topic 2: job mental health back home since house didnt last told\n",
      "Topic 3: someone depression thoughts mental talk person love self good thing\n",
      "Topic 4: anymore everything hate never tired every happy fucking better good\n",
      "Topic 5: school didnt never deleted user friend parents mom said told\n",
      "\n",
      "==================================================\n",
      " Post-COVID Topics (n=6218 posts) \n",
      "==================================================\n",
      "Topic 1: end talk didnt someone say said friend never thing told\n",
      "Topic 2: job never mental live love mom parents health school hate\n",
      "Topic 3: depression better anymore everything thoughts good bad happy tired never\n",
      "Topic 4: anxiety heart symptoms sleep also pain panic back scared health\n",
      "Topic 5: anxiety panic home also anxious take night attacks back attack\n"
     ]
    }
   ],
   "source": [
    "display_topics(pre_covid_df, 'full_text', title=\"Pre-COVID Topics\")\n",
    "display_topics(during_covid_df, 'full_text', title=\"During-COVID Topics\")\n",
    "display_topics(post_covid_df, 'full_text', title=\"Post-COVID Topics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fa3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
